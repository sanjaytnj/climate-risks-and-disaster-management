{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43641c37",
   "metadata": {},
   "source": [
    "# AI‑Powered Climate Risk Travel Planner\n",
    "\n",
    "**A detailed internship-ready project notebook**\n",
    "\n",
    "**Contents:** project overview, objectives, architecture, data schema, ML prototype (synthetic), API skeletons, deployment notes, milestones, and deliverables.\n",
    "\n",
    "**Author:** Internship Candidate\n",
    "\n",
    "**Date:** 2025-09-07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f40097",
   "metadata": {},
   "source": [
    "## 1. One-line summary\n",
    "A web/mobile app that gives travelers an AI-driven **risk score** (0–100) for a destination/date, real-time disaster alerts, alternatives/recommendations, and emergency support info."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1565f4f",
   "metadata": {},
   "source": [
    "## 2. Objectives (measurable)\n",
    "- Short-term travel risk score (0–100) for destination/date.\n",
    "- Real-time alerts for ongoing disasters.\n",
    "- Recommend 3 actionable options: keep, reschedule, alternative.\n",
    "- Provide emergency contacts and guidance.\n",
    "- Deliver working prototype (frontend + backend + ML) by internship end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0bebf0",
   "metadata": {},
   "source": [
    "## 3. High-level architecture\n",
    "1. Frontend: React / React Native UI\n",
    "2. Backend: FastAPI (recommended) or Flask\n",
    "3. Ingest: weather APIs, disaster feeds (GDACS/NDMA), satellite indices (optional)\n",
    "4. DB / Feature store: PostgreSQL or MongoDB\n",
    "5. ML module: model server returning risk_score & explanation\n",
    "6. Notifications: Push/Twilio/email\n",
    "7. Monitoring: simple logs / Prometheus & Grafana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70761b67",
   "metadata": {},
   "source": [
    "## 4. Data schema (recommended columns)\n",
    "`date, lat, lon, temp_c, precip_24h_mm, precip_72h_mm, wind_kmph, humidity_pct, aqi, river_level_m, sea_level_pressure_hpa, soil_moisture, historical_flood_count_5yr, elevation_m, landcover_type, is_cyclone_warning, is_excess_rain_advisory, label_risk`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa50c35",
   "metadata": {},
   "source": [
    "## 5. Feature ideas & sources\n",
    "- Precipitation (forecast & recent accumulation) — OpenWeatherMap, IMD\n",
    "- Wind gusts — weather APIs\n",
    "- Wind gusts — weather APIs\n",
    "- River gauge levels — local hydrology APIs (if available)\n",
    "- AQI — local monitoring networks\n",
    "- Satellite flood index — Sentinel-derived indices (optional)\n",
    "- Historical disaster frequency — EM-DAT, local records\n",
    "- Elevation & landcover — SRTM / global landcover datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94672704",
   "metadata": {},
   "source": [
    "## 6. Baseline ML prototype (synthetic data)\n",
    "The cell below trains a RandomForest baseline on synthetic features, evaluates it, and saves a small sample CSV. Replace synthetic data with real features when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51365781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline ML prototype using synthetic data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "N = 1500\n",
    "df = pd.DataFrame({\n",
    "    'date': pd.date_range('2024-01-01', periods=N, freq='H').strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'lat': np.random.uniform(-90, 90, N),\n",
    "    'lon': np.random.uniform(-180, 180, N),\n",
    "    'temp_c': np.random.normal(25, 8, N),\n",
    "    'precip_24h_mm': np.random.exponential(5, N),\n",
    "    'precip_72h_mm': np.random.exponential(12, N),\n",
    "    'wind_kmph': np.random.normal(15, 10, N).clip(0),\n",
    "    'humidity_pct': np.random.uniform(30, 100, N),\n",
    "    'aqi': np.random.uniform(10, 400, N),\n",
    "    'river_level_m': np.random.normal(2, 1, N).clip(0),\n",
    "    'sea_level_pressure_hpa': np.random.normal(1013, 10, N),\n",
    "    'elevation_m': np.random.uniform(0, 3000, N)\n",
    "})\n",
    "\n",
    "df['label_risk'] = 0\n",
    "df.loc[(df['precip_72h_mm'] > 50) | (df['wind_kmph'] > 70) | (df['river_level_m'] > 6), 'label_risk'] = 2\n",
    "df.loc[((df['precip_72h_mm'] > 20) & (df['precip_24h_mm'] > 10)) | (df['wind_kmph'] > 40), 'label_risk'] = 1\n",
    "\n",
    "features = ['temp_c','precip_24h_mm','precip_72h_mm','wind_kmph','humidity_pct','aqi','river_level_m','sea_level_pressure_hpa','elevation_m']\n",
    "X = df[features]\n",
    "y = df['label_risk']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Classification report:\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "importances = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "print('\\nFeature importances:\\n', importances)\n",
    "\n",
    "os.makedirs('/mnt/data/model_output', exist_ok=True)\n",
    "joblib.dump(model, '/mnt/data/model_output/risk_model_rf.pkl')\n",
    "X_test.head(50).to_csv('/mnt/data/model_output/sample_test_features.csv', index=False)\n",
    "print('\\nSaved model and sample CSV to /mnt/data/model_output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995e1a5",
   "metadata": {},
   "source": [
    "## 7. Simple explainability\n",
    "Use feature importances above now. For per-prediction explanations, integrate SHAP or LIME when packaging the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbeaa6a",
   "metadata": {},
   "source": [
    "## 8. API skeletons (FastAPI / Flask)\n",
    "Use the skeletons in code cells to start your backend. Replace placeholder features with real features computed from API pulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba012e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAPI skeleton (example)\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "app = FastAPI()\n",
    "try:\n",
    "    model = joblib.load('/mnt/data/model_output/risk_model_rf.pkl')\n",
    "except:\n",
    "    model = None\n",
    "\n",
    "class RiskRequest(BaseModel):\n",
    "    lat: float\n",
    "    lon: float\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    travelers: int = 1\n",
    "    special_needs: list = []\n",
    "\n",
    "@app.post('/risk')\n",
    "def get_risk(req: RiskRequest):\n",
    "    # Replace the following with real feature extraction\n",
    "    features = np.array([[25.0, 10.0, 30.0, 15.0, 70.0, 100.0, 2.0, 1012.0, 50.0]])\n",
    "    if model is not None:\n",
    "        pred = model.predict_proba(features)\n",
    "        risk_score = float(pred[0].dot(np.arange(len(pred[0])))/ (len(pred[0])-1) * 100) if pred.shape[1]>1 else float(pred[0].max()*100)\n",
    "        risk_level = 'High' if risk_score>66 else ('Medium' if risk_score>33 else 'Low')\n",
    "    else:\n",
    "        risk_score = 42.0\n",
    "        risk_level = 'Medium'\n",
    "    return {'risk_score': risk_score, 'risk_level': risk_level}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask skeleton (example)\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib, numpy as np\n",
    "app = Flask(__name__)\n",
    "try:\n",
    "    model = joblib.load('/mnt/data/model_output/risk_model_rf.pkl')\n",
    "except:\n",
    "    model = None\n",
    "\n",
    "@app.route('/risk', methods=['POST'])\n",
    "def risk():\n",
    "    data = request.json or {}\n",
    "    features = np.array([[25.0, 5.0, 12.0, 10.0, 60.0, 80.0, 1.5, 1010.0, 100.0]])\n",
    "    if model is not None:\n",
    "        pred = model.predict_proba(features)\n",
    "        risk_score = float(pred[0].dot(np.arange(len(pred[0])))/ (len(pred[0])-1) * 100) if pred.shape[1]>1 else float(pred[0].max()*100)\n",
    "        risk_level = 'High' if risk_score>66 else ('Medium' if risk_score>33 else 'Low')\n",
    "    else:\n",
    "        risk_score = 25.0\n",
    "        risk_level = 'Low'\n",
    "    return jsonify({'risk_score': risk_score, 'risk_level': risk_level})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992525e7",
   "metadata": {},
   "source": [
    "## 9. Notifications & alerting\n",
    "- Scheduler (APScheduler/Celery) to poll feeds and compute user-specific alerts.\n",
    "- Use Twilio / Firebase Cloud Messaging for SMS/push.\n",
    "- Always include official feed links and confidence scores in alerts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60c6fe",
   "metadata": {},
   "source": [
    "## 10. Evaluation & metrics\n",
    "- Class metrics (precision/recall/F1), calibration (Brier), historical-event matching. Include user feedback for continual improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025f1a3",
   "metadata": {},
   "source": [
    "## 11. 8-week milestone plan\n",
    "Week 1: Setup & mockups\n",
    "Week 2: Ingest & DB\n",
    "Week 3: Baseline model\n",
    "Week 4: Backend & /risk\n",
    "Week 5: Emergency info & alerts\n",
    "Week 6: Explainability & refine\n",
    "Week 7: Frontend polish\n",
    "Week 8: Finalize & demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c38f96",
   "metadata": {},
   "source": [
    "## 12. Deliverables\n",
    "- Working demo, notebooks, API endpoints, README, slides, optional demo video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b502819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small README file written alongside the notebook\n",
    "readme = \"\"\"AI-Powered Climate Risk Travel Planner\n",
    "Files to look for after running cells:\n",
    "- /mnt/data/model_output/risk_model_rf.pkl\n",
    "- /mnt/data/model_output/sample_test_features.csv\n",
    "Run the ML prototype cell to generate these files.\n",
    "\"\"\n",
    "open('/mnt/data/AI_Powered_Climate_Risk_Travel_Planner_README.txt','w').write(readme)\n",
    "print('Wrote README to /mnt/data/AI_Powered_Climate_Risk_Travel_Planner_README.txt')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
